{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41391e00-bdd1-4845-bd8f-1a5b2e83880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"ray[serve]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b12abb1f-6ee5-4f7c-9cb8-a1487771e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7190731-5521-46c2-8007-bce0ab278e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m ERROR 2025-03-06 10:56:32,938 default_OnlinePredictor dqh1myds 3bbf6b5f-614d-473b-b522-78ee43fffa98 -- Request failed.\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 472, in _handle_errors_and_metrics\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     yield _status_code_callback\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 880, in _wrap_user_method_call\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     yield status_code_callback\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 646, in handle_request_with_rejection\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     async for result in self._call_user_generator(\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 583, in _call_user_generator\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     raise e from None\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 1608, in call_user_method\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     result, sync_gen_consumed = await self._call_func_or_gen(\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 1326, in _call_func_or_gen\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     result = await result\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m              ^^^^^^^^^^^^\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/var/folders/b3/pn0wt8fs0f1b_5r58bpv7j1m0000gp/T/ipykernel_58519/2402946704.py\", line 16, in __call__\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m NameError: name 'batch' is not defined\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m INFO 2025-03-06 10:56:32,939 default_OnlinePredictor dqh1myds 3bbf6b5f-614d-473b-b522-78ee43fffa98 -- POST / 500 5.4ms\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m ERROR 2025-03-06 11:02:33,725 default_OnlinePredictor dqh1myds 3d4e47b5-59bc-4ffd-8eaf-2e6ec1d62f6f -- Request failed.\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 472, in _handle_errors_and_metrics\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     yield _status_code_callback\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 880, in _wrap_user_method_call\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     yield status_code_callback\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 646, in handle_request_with_rejection\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     async for result in self._call_user_generator(\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 583, in _call_user_generator\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     raise e from None\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 1608, in call_user_method\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     result, sync_gen_consumed = await self._call_func_or_gen(\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/Users/justin/miniconda3/envs/ai-computing/lib/python3.11/site-packages/ray/serve/_private/replica.py\", line 1326, in _call_func_or_gen\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m     result = await result\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m              ^^^^^^^^^^^^\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m   File \"/var/folders/b3/pn0wt8fs0f1b_5r58bpv7j1m0000gp/T/ipykernel_58519/2402946704.py\", line 16, in __call__\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m NameError: name 'batch' is not defined\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58582)\u001b[0m INFO 2025-03-06 11:02:33,726 default_OnlinePredictor dqh1myds 3d4e47b5-59bc-4ffd-8eaf-2e6ec1d62f6f -- POST / 500 5.8ms\n",
      "\u001b[36m(ServeController pid=58580)\u001b[0m INFO 2025-03-06 11:03:52,509 controller 58580 -- Deploying new version of Deployment(name='OnlinePredictor', app='default') (initial target replicas: 1).\n",
      "\u001b[36m(ServeController pid=58580)\u001b[0m INFO 2025-03-06 11:03:52,618 controller 58580 -- Stopping 1 replicas of Deployment(name='OnlinePredictor', app='default') with outdated versions.\n",
      "\u001b[36m(ServeController pid=58580)\u001b[0m INFO 2025-03-06 11:03:52,618 controller 58580 -- Adding 1 replica to Deployment(name='OnlinePredictor', app='default').\n",
      "\u001b[36m(ServeController pid=58580)\u001b[0m INFO 2025-03-06 11:03:54,687 controller 58580 -- Replica(id='dqh1myds', deployment='OnlinePredictor', app='default') is stopped.\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58626)\u001b[0m INFO 2025-03-06 11:04:04,544 default_OnlinePredictor z7d9brr7 053fddde-45b6-40e4-8628-52da5c0e1adb -- POST / 200 9.0ms\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58626)\u001b[0m INFO 2025-03-06 11:04:12,501 default_OnlinePredictor z7d9brr7 095bbe40-38ed-4294-95e6-8904438cc6a5 -- POST / 200 6.4ms\n",
      "\u001b[36m(ServeReplica:default:OnlinePredictor pid=58626)\u001b[0m INFO 2025-03-06 11:04:17,452 default_OnlinePredictor z7d9brr7 7f34c299-499f-487b-bf95-60383bd8d5d5 -- POST / 200 7.3ms\n",
      "\u001b[36m(ServeController pid=58580)\u001b[0m INFO 2025-03-06 11:05:21,719 controller 58580 -- Removing 1 replica from Deployment(name='OnlinePredictor', app='default').\n",
      "\u001b[36m(ServeController pid=58580)\u001b[0m INFO 2025-03-06 11:05:23,795 controller 58580 -- Replica(id='z7d9brr7', deployment='OnlinePredictor', app='default') is stopped.\n"
     ]
    }
   ],
   "source": [
    "dataset = ray.data.read_parquet(\"nyc_taxi_2021.parquet\")\n",
    "dataset = dataset.drop_columns(['__index_level_0__'])\n",
    "train_ds, test_ds = dataset.train_test_split(test_size=0.3)\n",
    "print(train_ds)\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef65634-fd28-40d9-89a8-7a9b2440515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.train import ScalingConfig, RunConfig\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "    label_column=\"is_big_tip\",\n",
    "    scaling_config=ScalingConfig(num_workers=4, use_gpu=False),\n",
    "    params={\"objective\": \"binary:logistic\"},\n",
    "    datasets={\"train\": train_ds, \"valid\": test_ds},\n",
    "    run_config=RunConfig(storage_path=\"/tmp/cluster_storage\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63fbc44d-9e1e-4a17-ad8b-14c959d46705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-03-06 10:43:45</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:28.68        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.3/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 5.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  params/max_depth</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  valid-logloss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_d8c4f_00000</td><td>TERMINATED</td><td>127.0.0.1:58545</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         11.1093</td><td style=\"text-align: right;\">       0.661042</td><td style=\"text-align: right;\">       0.661374</td></tr>\n",
       "<tr><td>XGBoostTrainer_d8c4f_00001</td><td>TERMINATED</td><td>127.0.0.1:58544</td><td style=\"text-align: right;\">                 9</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         11.4912</td><td style=\"text-align: right;\">       0.657311</td><td style=\"text-align: right;\">       0.658964</td></tr>\n",
       "<tr><td>XGBoostTrainer_d8c4f_00002</td><td>TERMINATED</td><td>127.0.0.1:58563</td><td style=\"text-align: right;\">                 9</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">          6.5924</td><td style=\"text-align: right;\">       0.657311</td><td style=\"text-align: right;\">       0.658964</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e866a335ff404c96c415cecb42f913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58556) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cab70b5853c4b76bb5ab06457329085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58556) - split(4, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914bc82c6d5f4e3390c445bdfe3cdc21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58555) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6842d2426447708987b60a1313f3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58555) - split(4, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3704fc5adcf94f8596eab92b47322980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58554) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd230cdce0ab481d834506114b32d6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58554) - split(4, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ea02fa0dc54d44a8069e70690f1b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58557) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a12dc00cc64bfaa780987ef0698c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58557) - split(4, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c07ecc8f3d04051a001c922d0c4095e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58568) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319ce335b31f4c59a1a56875e43190f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58568) - split(4, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f7711deef64e838c7d25d97d792fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58569) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6ac3f26ba94f988d2df082ca35face",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=58569) - split(4, equal=True) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 10:43:45,203\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/tmp/cluster_storgage/XGBoostTrainer_2025-03-06_10-43-16' in 0.0097s.\n",
      "2025-03-06 10:43:45,209\tINFO tune.py:1041 -- Total run time: 28.70 seconds (28.67 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune import Tuner, TuneConfig\n",
    "\n",
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space={\"params\": {\"max_depth\": tune.randint(2, 12)}},\n",
    "    tune_config=TuneConfig(num_samples=3, metric=\"valid-logloss\", mode=\"min\"),\n",
    "    run_config=RunConfig(storage_path=\"/tmp/cluster_storgage/\")\n",
    ")\n",
    "checkpoint = tuner.fit().get_best_result().checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e678015a-59f5-4c0e-be00-5b52730df715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import pandas as pd\n",
    "\n",
    "class OfflinePredictor:\n",
    "    def __init__(self):\n",
    "        self._model = xgboost.Booster()\n",
    "        self._model.load_model(checkpoint.path + \"/model.ubj\")\n",
    "\n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        dmatrix = xgboost.DMatrix(pd.DataFrame(batch))\n",
    "        prediction = self._model.predict(dmatrix)\n",
    "        return {\"prediction\": prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd7c331-b5d3-4c4c-af65-75756e6e7a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 10:43:48,997\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-03-06_10-42-52_512282_58519/logs/ray-data\n",
      "2025-03-06 10:43:48,998\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> ActorPoolMapOperator[MapBatches(drop_columns)->MapBatches(OfflinePredictor)] -> LimitOperator[limit=20]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289dde664cf94ec3be896d6ac3ad5f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e767e6ebd14695b30040151893d634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(drop_columns)->MapBatches(OfflinePredictor) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fadc789645042b29ca54ed6ca1bb198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=20 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': array([0.62117326, 0.6351201 , 0.53432137, 0.63928   , 0.55415016,\n",
       "        0.5599472 , 0.6341473 , 0.628925  , 0.6034618 , 0.56432724,\n",
       "        0.53527355, 0.5456829 , 0.6368325 , 0.61181074, 0.55794364,\n",
       "        0.61181074, 0.54065686, 0.52323276, 0.49547666, 0.59156513],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_features = test_ds.drop_columns(['is_big_tip'])\n",
    "predicted_prob = test_ds_features.map_batches(OfflinePredictor, concurrency=2)\n",
    "predicted_prob.take_batch(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ebd41-8018-4b40-b8b9-617c1bb2d476",
   "metadata": {},
   "source": [
    "## Serve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be1d8869-5c68-4ed5-98b6-50592450fe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-03-06 11:03:52,422 serve 58519 -- Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n",
      "INFO 2025-03-06 11:03:57,466 serve 58519 -- Application 'default' is ready at http://127.0.0.1:8000/.\n",
      "INFO 2025-03-06 11:03:57,467 serve 58519 -- Deployed app 'default' successfully.\n"
     ]
    }
   ],
   "source": [
    "from ray import serve\n",
    "from starlette.requests import Request\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "@serve.deployment\n",
    "class OnlinePredictor:\n",
    "    def __init__(self, checkpoint):\n",
    "        self._model = xgboost.Booster()\n",
    "        self._model.load_model(checkpoint.path + \"/model.ubj\")\n",
    "\n",
    "    async def __call__(self, request: Request) -> dict:\n",
    "        req = await request.json()\n",
    "        data = json.loads(req)\n",
    "        dmatrix = xgboost.DMatrix(pd.DataFrame(data))\n",
    "        prediction = self._model.predict(dmatrix)\n",
    "        return {\"prediction\": prediction}\n",
    "\n",
    "handle = serve.run(OnlinePredictor.bind(checkpoint=checkpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c982328-ee89-43db-abe8-cdf8dd22abf1",
   "metadata": {},
   "source": [
    "### Make request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e090b2e-875f-42f1-83d2-2f44f0fefd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 11:04:17,264\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2025-03-06_10-42-52_512282_58519/logs/ray-data\n",
      "2025-03-06 11:04:17,265\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(drop_columns)] -> LimitOperator[limit=10]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec15248ec7414201bbb2105194a629f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4443c885ce54f86a78fdd63f390b0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(drop_columns) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bd9452652a454da2ae7d88294c6274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=10 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': [0.6211732625961304,\n",
       "  0.6351200938224792,\n",
       "  0.5343213677406311,\n",
       "  0.6392800211906433,\n",
       "  0.5541501641273499,\n",
       "  0.5599471926689148,\n",
       "  0.6341472864151001,\n",
       "  0.6289250254631042,\n",
       "  0.6034618020057678,\n",
       "  0.5643272399902344]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "sample_batch = test_ds_features.take_batch(10)\n",
    "data = pd.DataFrame(sample_batch).to_json(orient=\"records\")\n",
    "\n",
    "requests.post(\"http://localhost:8000/\", json=data).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6832984-8ec7-4ac6-ac48-dd40c1afa1d3",
   "metadata": {},
   "source": [
    "### Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31395a6d-c5fa-47d2-ac5f-9b772fe7c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
